{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you already have the word weights, you can use these to influence the summarization process directly. Below is a Python implementation using a BART model for summarization, with your word weights influencing the final output.\n",
    "\n",
    "Step 1: Prepare the Sentiment-Weighted Input\n",
    "Youâ€™ll first modify the input text based on your pre-calculated word weights to emphasize more important words during the summarization process.\n",
    "\n",
    "Step 2: Use a Pre-trained Summarization Model (BART)\n",
    "The following code assumes you have your word weights ready and want to use them to generate summaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# Pre-trained BART model\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Your input review and word weights\n",
    "review = \"The hotel was great, loved the view but the room was small.\"\n",
    "word_weights = {'hotel': 0.8, 'great': 0.7, 'loved': 0.6, 'view': 0.9, 'room': 0.4, 'small': -0.5}\n",
    "\n",
    "def apply_word_weights(review, word_weights):\n",
    "    words = review.split()\n",
    "    weighted_review = []\n",
    "    for word in words:\n",
    "        weight = word_weights.get(word.lower(), 0)  # Get the word weight\n",
    "        if weight > 0:\n",
    "            weighted_review.append(f\"{word} very\")\n",
    "        elif weight < 0:\n",
    "            weighted_review.append(f\"not {word}\")\n",
    "        else:\n",
    "            weighted_review.append(word)\n",
    "    return \" \".join(weighted_review)\n",
    "\n",
    "# Apply weights to review text\n",
    "weighted_review = apply_word_weights(review, word_weights)\n",
    "\n",
    "# Tokenize and generate the summary\n",
    "inputs = tokenizer.encode(weighted_review, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "summary_ids = model.generate(inputs, max_length=50, min_length=30, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Original Review:\", review)\n",
    "print(\"Weighted Review:\", weighted_review)\n",
    "print(\"Summary:\", summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "Word Weight Application: The function apply_word_weights modifies the review by emphasizing words with positive weights and de-emphasizing or negating words with negative weights.\n",
    "Tokenization & Summarization: The weighted_review is then tokenized and passed to the BART model, which generates a summary considering these weights.\n",
    "Customization:\n",
    "Weight Impact: You can adjust how much the weights influence the review text. For example, you can repeat words with higher weights or add specific tokens.\n",
    "Fine-tuning: If you require even more control, consider fine-tuning the BART model on a dataset where the summaries are influenced by similar weighted inputs.\n",
    "This approach should help you create summaries that reflect the sentiment importance of specific words within the text."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
